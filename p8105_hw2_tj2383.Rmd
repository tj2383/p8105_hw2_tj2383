---
title: "p8105_hw2_tj2383"
author: "Tanvi Jain"
date: "9/25/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

## Problem 1

Read in and clean the transit dataset:
```{r cleaning}
transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = "cccddcccccccccccccccccccccccddcc") %>% 
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```
According to the "cleaning" code chunk, this dataset was first imported using the read_csv statement. I then cleaned the variable names so that they were converted to lower case and the snake format. I further cleaned the dataset by selecting key variables to include in the dataset; `line`, `station_name`, `station_latitude`, `station_longitude`, `route1`, `route2`, `route3`, `route4`, `route5`, `route6`, `route7`, `route8`, `route9`, `route10`, `route11`, `entry`, `vending`, `entrance_type`, and `ada`. Lastly, I changed the `entry` variable from a character variable to a logical variable. The dimensions (rows, columns) of this dataset are `r dim(transit_data)`. While I did some cleaning, this dataset is still not entirely tidy. For example, there are several "route" variables that span multiple columns and instead could be consolidated to show one column called `route` and the value for each route in another column.


The following "problem1_q" code chunk answers questions about transit_data:
```{r problem1_q}
transit_data %>% 
  distinct(line, station_name) 

select(transit_data, line, station_name, ada) %>% 
  filter(ada == "TRUE") %>% 
  distinct(line, station_name, ada)

select(transit_data, entry, vending) %>% 
  filter(vending == "NO", entry == TRUE) %>% 
  summarize(sum(entry))

select(transit_data, entry) %>% 
  filter(entry == TRUE) %>% 
  summarize(sum(entry))
```
According to the problem1_q code chunk, there are `r count(distinct(transit_data, line, station_name))` distinct stations. There are `r count(select(transit_data, line, station_name, ada) %>% 
  filter(ada == "TRUE") %>% 
  distinct(line, station_name, ada))` ADA compliant stations. The proportion of station entrace/exits with no vending is `r (69 / 1753) `.


The following "reformat_transit" code chunk reformatted data so that route number and route name are distinct variables. Then I calculated the number of distinct stations serving the A train and how many of them are ADA compliant.
```{r reformat_transit}
reformat_transit_data = 
  transit_data %>% 
  gather(key = route_number, value = route_name, route1:route11)

select(reformat_transit_data, route_name, station_name, line) %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name)

select(reformat_transit_data, route_name, station_name, line, ada) %>% 
  filter(route_name == "A", ada == "TRUE") %>% 
  distinct(line, station_name)
```
There are 60 distinct stations that serve the A train. 17 of these stations are ADA compliant.

## Problem 2

Read in and clean the Mr.Trash Wheel dataset
```{r}
trashwheel_data = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", "Mr. Trash Wheel", range = cellranger::cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))

trashwheel_data %>% 
  filter(year == "2016") %>% 
  summarize(median(sports_balls))
```
According to this code chunk, I specified the sheet in the Excel file and omited columns containing notes, cleaned the variables to be lowercase snake, omitted rows with no dumpster-specific data, and rounded the number of `sports_balls` to the nearest integer and converted it to an integer variable.


In the following code chunk I read in and cleaned 2016 and 2017 Precipitation datasets. For each, I omitted rows without precipitation data and added a variable, `year`. I renamed the variable "precipitation_in" to `month` and the variable "x_in" to `rainfall_in`. Next, I combined the datasets to create precipitation_16_17_data and converted `month` to a character variable.
```{r}
precipitation16_data = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", "2016 Precipitation", range = cellranger::cell_cols("A:B")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(precipitation_in) & precipitation_in != ("Month")) %>% 
  add_column(year = "2016") %>% 
  rename(month = precipitation_in) %>% 
  rename(rainfall_in = x_1) %>% 
  mutate(rainfall_in = as.numeric(rainfall_in))

precipitation17_data = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx", "2017 Precipitation", range = cellranger::cell_cols("A:B")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(precipitation_in) & !is.na(x_1) & precipitation_in != ("Month")) %>% 
  add_column(year = "2017") %>% 
  rename(month = precipitation_in) %>% 
  rename(rainfall_in = x_1) %>% 
  mutate(rainfall_in = as.numeric(rainfall_in)) 

precipitation17_data %>% 
  select(rainfall_in) %>% 
  sum()

precipitation_16_17_data = bind_rows(precipitation16_data, precipitation17_data) %>% 
  mutate(month = month.name[as.integer(month)])
```
The two original datasets, 2016 Precipitation and 2017 Precipitation were cleaned and combined to make 2016/2017 Precipitation data (precipitation_16_17_data). There are `r nrow(precipitation16_data) ` observations in the 2016 dataset and `r nrow(precipitation17_data) ` observations in the 2017 dataset. The key variables in this dataset include `month` which indicates the month and `rainfall_in` which indicates the rainfall amount in inches. The total precipitation for 2017 was `r precipitation17_data %>% select(rainfall_in) %>% sum()` inches. The median number of sports balls in 2016 from the trashwheel_data was `r trashwheel_data %>% filter(year == "2016") %>% summarize(median(sports_balls))`.

## Problem 3

In the following code chunk I read in the data:
1. formatted the data to use appropriate variable names;
focused on the “Overall Health” topic
2. excluded variables for `class`, `topic`, `question`, `sample_size`, and everything from `confidence_limit_low` to `geo_location`
3. structured data so that values for Response (“Excellent” to “Poor”) are column names/variables which indicate the proportion of subjects with each response (which are values of Data_value in the original dataset)
4. created a new variable showing the proportion of responses that were “Excellent” or “Very Good” called `proportion_excellent_verygood`
```{r}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("brfss_smart2010")

brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names()

brfss_data %>% 
  mutate(proportion_excellent_verygood = (excellent + very_good)) %>% 
  filter(year == "2002", !is.na(excellent))

brfss_data %>% 
  distinct(locationabbr) %>% 
  count()

brfss_data %>% 
  count(locationabbr) %>% 
  arrange(desc(n)) %>% 
  select(locationabbr) %>% 
  head(1)
```
According to the brfss_dataset there are `r count(distinct(brfss_data, locationdesc))` unique locations. Yes, all states are represented, determined by counting the number of values for `locationabbr` which is `r brfss_data %>% distinct(locationabbr) %>% count()` including Washington D.C. The state observed the most was `r brfss_data %>% count(locationabbr) %>% arrange(desc(n)) %>% 
select(locationabbr) %>% head(1)`. In 2002, the median of the "Excellent" response value was `r brfss_data %>% filter(year == "2002", !is.na(excellent)) %>% 
  summarize(median(excellent))`.

The following is a histogram of the `excellent` response values in 2002.
```{r}
brfss_data %>% 
  filter(year == "2002", !is.na(excellent)) %>% 
  ggplot(aes(x = excellent)) + geom_histogram()
```

The following is a scatterplot of the proportion of `Excellent` response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010:
```{r}
brfss_data %>% 
  filter(locationdesc == "NY - Queens County" | locationdesc == "NY - New York County") %>% 
  ggplot(aes(x = year, y = excellent, color = locationdesc)) + geom_point()
```


