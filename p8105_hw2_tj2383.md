p8105\_hw2\_tj2383
================
Tanvi Jain
9/25/2018

Problem 1
---------

Read in and clean the transit dataset:

``` r
transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = "cccddcccccccccccccccccccccccddcc") %>% 
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, route1:route11, entry, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

According to the cleaning code chunk, this dataset was first imported using the read\_csv statement. I then cleaned the variable names so that they were converted to lower case and the snake format, this makes the variables easy to use while coding. I further cleaned the dataset by selecting key variables to include in the dataset; line, station name, station latitude, station longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance\_type, and ada. Lastly, I changed the "entry" variable from a character variable to a logical variable. The dimensions of this dataset are 1868, 19. This dataset is still not tidy. For example, there are several "route" variables that could be consolidated.

The following were conducted in this code chunk: -How many distinct stations are there? -How many stations are ADA compliant? -What proportion of station entrances / exits without vending allow entrance? -Reformat data so that route number and route name are distinct variables. How many distinct stations serve the A train? How many are ADA compliant?

``` r
transit_data %>% 
  distinct(line, station_name) 
```

    ## # A tibble: 465 x 2
    ##    line     station_name            
    ##    <chr>    <chr>                   
    ##  1 4 Avenue 25th St                 
    ##  2 4 Avenue 36th St                 
    ##  3 4 Avenue 45th St                 
    ##  4 4 Avenue 53rd St                 
    ##  5 4 Avenue 59th St                 
    ##  6 4 Avenue 77th St                 
    ##  7 4 Avenue 86th St                 
    ##  8 4 Avenue 95th St                 
    ##  9 4 Avenue 9th St                  
    ## 10 4 Avenue Atlantic Av-Barclays Ctr
    ## # ... with 455 more rows

``` r
select(transit_data, line, station_name, ada) %>% 
  filter(ada == "TRUE") %>% 
  distinct(line, station_name, ada)
```

    ## # A tibble: 84 x 3
    ##    line            station_name                   ada  
    ##    <chr>           <chr>                          <chr>
    ##  1 4 Avenue        Atlantic Av-Barclays Ctr       TRUE 
    ##  2 4 Avenue        DeKalb Av                      TRUE 
    ##  3 4 Avenue        Pacific St                     TRUE 
    ##  4 42nd St Shuttle Grand Central                  TRUE 
    ##  5 6 Avenue        34th St                        TRUE 
    ##  6 6 Avenue        47-50th Sts Rockefeller Center TRUE 
    ##  7 6 Avenue        Church Av                      TRUE 
    ##  8 63rd Street     21st St                        TRUE 
    ##  9 63rd Street     Lexington Av                   TRUE 
    ## 10 63rd Street     Roosevelt Island               TRUE 
    ## # ... with 74 more rows

``` r
select(transit_data, entry, vending) %>% 
  filter(vending == "NO") %>% 
  summarize(mean(entry))
```

    ## # A tibble: 1 x 1
    ##   `mean(entry)`
    ##           <dbl>
    ## 1         0.377

According to the problem1\_q code chunk, there are 465 distinct stations. There are 84 ADA compliant stations. The proportion of station entrace/exits with no vending are 0.3770492.

In this code chunk reformatted data so that route number and route name are distinct variables. Then I calculated the number of distinct stations serve the A train and how many of them are ADA compliant.

``` r
reformat_transit_data = 
  transit_data %>% 
  gather(key = route_number, value = route_name, route1:route11)

select(reformat_transit_data, route_name, station_name, line) %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name)
```

    ## # A tibble: 60 x 2
    ##    station_name                  line           
    ##    <chr>                         <chr>          
    ##  1 Times Square                  42nd St Shuttle
    ##  2 125th St                      8 Avenue       
    ##  3 145th St                      8 Avenue       
    ##  4 14th St                       8 Avenue       
    ##  5 168th St - Washington Heights 8 Avenue       
    ##  6 175th St                      8 Avenue       
    ##  7 181st St                      8 Avenue       
    ##  8 190th St                      8 Avenue       
    ##  9 34th St                       8 Avenue       
    ## 10 42nd St                       8 Avenue       
    ## # ... with 50 more rows

``` r
select(reformat_transit_data, route_name, station_name, line, ada) %>% 
  filter(route_name == "A", ada == "TRUE") %>% 
  distinct(line, station_name)
```

    ## # A tibble: 17 x 2
    ##    station_name                  line            
    ##    <chr>                         <chr>           
    ##  1 14th St                       8 Avenue        
    ##  2 168th St - Washington Heights 8 Avenue        
    ##  3 175th St                      8 Avenue        
    ##  4 34th St                       8 Avenue        
    ##  5 42nd St                       8 Avenue        
    ##  6 59th St                       8 Avenue        
    ##  7 Inwood - 207th St             8 Avenue        
    ##  8 West 4th St                   8 Avenue        
    ##  9 World Trade Center            8 Avenue        
    ## 10 Times Square-42nd St          Broadway        
    ## 11 59th St-Columbus Circle       Broadway-7th Ave
    ## 12 Times Square                  Broadway-7th Ave
    ## 13 8th Av                        Canarsie        
    ## 14 Franklin Av                   Franklin        
    ## 15 Euclid Av                     Fulton          
    ## 16 Franklin Av                   Fulton          
    ## 17 Howard Beach                  Rockaway

There are 60 distinct stations that serve the A train. 17 of these stations are ADA compliant.

Problem 2
---------

Read in and clean the Mr.Trash Wheel dataset

``` r
trashwheel_data = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", "Mr. Trash Wheel", range = cellranger::cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(sports_balls = as.integer(round(sports_balls)))

trashwheel_data %>% 
  filter(year == "2016") %>% 
  summarize(median(sports_balls))
```

    ## # A tibble: 1 x 1
    ##   `median(sports_balls)`
    ##                    <int>
    ## 1                     26

In this code chunk I read in and cleaned 2016 and 2017 Precipitation datasets. For each, I omitted rows without precipitation data and added a variable, `year`. I renamed the variables "precipitation\_in" and "x\_in". Next, I combined the datasets and converted month to a character variable.

``` r
precipitation16_data = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", "2016 Precipitation", range = cellranger::cell_cols("A:B")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(precipitation_in) & precipitation_in != ("Month")) %>% 
  add_column(year = "2016") %>% 
  rename(month = precipitation_in) %>% 
  rename(rainfall_in = x_1) %>% 
  mutate(rainfall_in = as.numeric(rainfall_in))

precipitation17_data = readxl::read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", "2017 Precipitation", range = cellranger::cell_cols("A:B")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(precipitation_in) & !is.na(x_1) & precipitation_in != ("Month")) %>% 
  add_column(year = "2017") %>% 
  rename(month = precipitation_in) %>% 
  rename(rainfall_in = x_1) %>% 
  mutate(rainfall_in = as.numeric(rainfall_in))

precipitation17_data %>% 
  select(rainfall_in) %>% 
  sum()
```

    ## [1] 29.93

``` r
precipitation_16_17_data = bind_rows(precipitation16_data, precipitation17_data) %>% 
  mutate(month = month.name[as.integer(month)]) 
```

The two original datasets, 2016 Precipitation and 2017 Precipitation were cleaned and combined to make 2016/2017 Precipitation data (precipitation\_16\_17\_data). There are 12 observations in the 2016 dataset and 8 observations in the 2017 dataset. The key variables in this dataset include `month` which indicates the month and `rainfall_in` which indicates the rainfall amount in inches. The total precipitation for 2017 was 29.93. The median sports balls in 2016 was 26.

Problem 3
---------

In this code chunk I read in the data then: -formatted the data to use appropriate variable names; focused on the “Overall Health” topic -excluded variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation -structured data so that values for Response (“Excellent” to “Poor”) are column names / variables which indicate the proportion of subjects with each response (which are values of Data\_value in the original dataset) -created a new variable showing the proportion of responses that were “Excellent” or “Very Good”

``` r
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (21f5ad1c) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)
data("brfss_smart2010")

brfss_data = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -confidence_limit_low:-geo_location) %>% 
  spread(key = response, value = data_value) %>% 
  janitor::clean_names()

brfss_data %>% 
  mutate(proportion_excellent_verygood = (excellent + very_good) / 100) %>% 
  filter(year == "2002", !is.na(excellent))
```

    ## # A tibble: 155 x 9
    ##     year locationabbr locationdesc excellent  fair  good  poor very_good
    ##    <int> <chr>        <chr>            <dbl> <dbl> <dbl> <dbl>     <dbl>
    ##  1  2002 AK           AK - Anchor…      27.9   8.6  23.8   5.9      33.7
    ##  2  2002 AL           AL - Jeffer…      18.5  12.1  32.7   5.9      30.9
    ##  3  2002 AR           AR - Pulask…      24.1  12.5  29.9   4.2      29.3
    ##  4  2002 AZ           AZ - Marico…      21.6  10.3  26.9   4.6      36.6
    ##  5  2002 AZ           AZ - Pima C…      26.6   7.5  31.9   3.9      30.1
    ##  6  2002 CA           CA - Los An…      22.7  14.3  28.7   4.5      29.8
    ##  7  2002 CO           CO - Adams …      21.2  14.4  29     4.2      31.2
    ##  8  2002 CO           CO - Arapah…      25.5   8    29.3   2.1      35.2
    ##  9  2002 CO           CO - Denver…      22.2  11.1  36.6   3        27.1
    ## 10  2002 CO           CO - Jeffer…      23.4  11.4  26.3   2.4      36.6
    ## # ... with 145 more rows, and 1 more variable:
    ## #   proportion_excellent_verygood <dbl>

``` r
brfss_data %>% 
  distinct(locationabbr)
```

    ## # A tibble: 51 x 1
    ##    locationabbr
    ##    <chr>       
    ##  1 AK          
    ##  2 AL          
    ##  3 AR          
    ##  4 AZ          
    ##  5 CA          
    ##  6 CO          
    ##  7 CT          
    ##  8 DC          
    ##  9 DE          
    ## 10 FL          
    ## # ... with 41 more rows

``` r
brfss_data %>% 
  count(locationabbr) %>% 
  arrange(desc(n)) %>% 
  select(locationabbr) %>% 
  head(1)
```

    ## # A tibble: 1 x 1
    ##   locationabbr
    ##   <chr>       
    ## 1 NJ

According to the brfss\_dataset there are 404 unique locations. Yes, all states are represented, determined by counting the number of values for `locationabbr` which is 51 including Washington D.C. The state observed the most was NJ. In 2002, the median of the "Excellent" response value was 23.6.
